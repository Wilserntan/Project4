{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Use Selenium and BeautifulSoup to read the contents of the HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "import random\n",
    "from time import sleep\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "options = Options()\n",
    "options.headless = True\n",
    "\n",
    "import os\n",
    "\n",
    "chromedriver = \"./chromedriver/chromedriver\"\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Obtain the hyperlinks for 4,000 Data related job roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, create an empty DataFrame with following columns.\n",
    "jobs = pd.DataFrame(columns=['link', 'employer', 'location', 'employment_type', 'seniority', 'sector', \n",
    "                             'pay_min', 'pay_max', 'pay_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: DeprecationWarning: use options instead of chrome_options\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "80\n",
      "100\n",
      "120\n",
      "140\n",
      "160\n",
      "180\n"
     ]
    }
   ],
   "source": [
    "for i in range (50,200):\n",
    "    \n",
    "    if i%20==0:\n",
    "        print (i)\n",
    "        \n",
    "    if i!=0 and i%50==0:\n",
    "            jobs.to_csv(\"./jobs{}.csv\" .format(i))\n",
    "    \n",
    "    # Set the URL we want to visit.\n",
    "    url = \"https://www.mycareersfuture.sg/search?search=data&sortBy=new_posting_date&page=\"+str(i)\n",
    "    \n",
    "    # Visit page with Selenium driver.\n",
    "    driver = webdriver.Chrome(executable_path=\"./chromedriver/chromedriver\", chrome_options=options)\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Wait 15 seconds.\n",
    "    sleep(15)\n",
    "\n",
    "    # Grab the page source.\n",
    "    html = driver.page_source\n",
    "    \n",
    "    # Pass page source to Beautifulsoup\n",
    "    listing = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # Close Driver\n",
    "    driver.close()\n",
    "\n",
    "    # The data we are looking for are all located in this tag and class\n",
    "    main = listing.find('div', {'class':'card-list'})\n",
    "    \n",
    "    # Loop through each entry.\n",
    "    for entry in main.find_all('div', id=True):\n",
    "\n",
    "        # Link\n",
    "        try:\n",
    "            link = entry.find('a', {'class':'bg-white mb3 w-100 dib v-top pa3 no-underline flex-ns flex-wrap JobCard__card___22xP3'})['href']\n",
    "        except:\n",
    "            link = np.nan\n",
    "        \n",
    "        # Employer\n",
    "        try:\n",
    "            employer = entry.find('p', {'name':'company'}).text\n",
    "        except:\n",
    "            employer = np.nan\n",
    "        \n",
    "        # Location\n",
    "        try:\n",
    "            location = entry.find('p', {'name':'location'}).text\n",
    "        except:\n",
    "            location = np.nan\n",
    "\n",
    "        # Employment Type\n",
    "        try:\n",
    "            employment_type = entry.find('p', {'name':'employment_type'}).text\n",
    "        except:\n",
    "            employment_type = np.nan\n",
    "\n",
    "        # Seniority\n",
    "        try:\n",
    "            seniority = entry.find('p', {'name':'seniority'}).text\n",
    "        except:\n",
    "            seniority = np.nan\n",
    "            \n",
    "        # Sector\n",
    "        try:\n",
    "            sector = entry.find('p', {'name':'category'}).text\n",
    "        except:\n",
    "            sector = np.nan\n",
    "            \n",
    "        # Min Pay\n",
    "        try:\n",
    "            pay_min = entry.find('div', {'class':'lh-solid'}).text.split('to')[0].replace('$','').replace(',','')\n",
    "        except:\n",
    "            pay_min = np.nan\n",
    "            \n",
    "        # Max Pay\n",
    "        try:\n",
    "            pay_max = entry.find('div', {'class':'lh-solid'}).text.split('to')[1].replace('$','').replace(',','')\n",
    "        except:\n",
    "            pay_max = np.nan\n",
    "            \n",
    "        # Pay Type\n",
    "        try:\n",
    "            pay_type = entry.find('span', {'class':'salary_type black-60 mv0 fw6 f5-5 lh-solid db pb2 dib i'}).text\n",
    "        except:\n",
    "            pay_type = np.nan\n",
    "            \n",
    "        # Update Dataframe with listing information\n",
    "        jobs.loc[len(jobs)] = [link, employer, location, employment_type, seniority, sector, pay_min, \n",
    "                               pay_max, pay_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = pd.read_csv(\"./jobs.csv\")\n",
    "\n",
    "jobs.drop(['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4000 entries, 0 to 3999\n",
      "Data columns (total 9 columns):\n",
      "link               4000 non-null object\n",
      "employer           4000 non-null object\n",
      "location           3856 non-null object\n",
      "employment_type    4000 non-null object\n",
      "seniority          3932 non-null object\n",
      "sector             4000 non-null object\n",
      "pay_min            3567 non-null float64\n",
      "pay_max            3567 non-null float64\n",
      "pay_type           3567 non-null object\n",
      "dtypes: float64(2), object(7)\n",
      "memory usage: 281.3+ KB\n"
     ]
    }
   ],
   "source": [
    "jobs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>employer</th>\n",
       "      <th>location</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>seniority</th>\n",
       "      <th>sector</th>\n",
       "      <th>pay_min</th>\n",
       "      <th>pay_max</th>\n",
       "      <th>pay_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/job/data-scientist-singapore-power-5731c18be1...</td>\n",
       "      <td>SINGAPORE POWER LIMITED</td>\n",
       "      <td>Central</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>Monthly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/job/senior-data-scientist-singapore-power-b8f...</td>\n",
       "      <td>SINGAPORE POWER LIMITED</td>\n",
       "      <td>Central</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Middle Management</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>14000.0</td>\n",
       "      <td>Monthly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/job/data-director-tbwa-singapore-14652381c7eb...</td>\n",
       "      <td>TBWA SINGAPORE PTE LTD</td>\n",
       "      <td>South</td>\n",
       "      <td>Permanent ...</td>\n",
       "      <td>Manager ...</td>\n",
       "      <td>Advertising / Media</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>Monthly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/job/head-data-engineering-fixed-mobile-09c037...</td>\n",
       "      <td>FIXED &amp; MOBILE PTE. LTD.</td>\n",
       "      <td>Central</td>\n",
       "      <td>Permanent ...</td>\n",
       "      <td>Senior Management</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>Monthly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/job/data-modeler-monarch-info-tech-services-9...</td>\n",
       "      <td>MONARCH INFO TECH SERVICES PTE. LTD.</td>\n",
       "      <td>Central</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>Monthly</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0  /job/data-scientist-singapore-power-5731c18be1...   \n",
       "1  /job/senior-data-scientist-singapore-power-b8f...   \n",
       "2  /job/data-director-tbwa-singapore-14652381c7eb...   \n",
       "3  /job/head-data-engineering-fixed-mobile-09c037...   \n",
       "4  /job/data-modeler-monarch-info-tech-services-9...   \n",
       "\n",
       "                               employer location employment_type  \\\n",
       "0               SINGAPORE POWER LIMITED  Central       Full Time   \n",
       "1               SINGAPORE POWER LIMITED  Central       Full Time   \n",
       "2                TBWA SINGAPORE PTE LTD    South   Permanent ...   \n",
       "3              FIXED & MOBILE PTE. LTD.  Central   Permanent ...   \n",
       "4  MONARCH INFO TECH SERVICES PTE. LTD.  Central       Full Time   \n",
       "\n",
       "           seniority                  sector  pay_min  pay_max pay_type  \n",
       "0       Professional  Information Technology   4000.0   8000.0  Monthly  \n",
       "1  Middle Management  Information Technology   8000.0  14000.0  Monthly  \n",
       "2        Manager ...    Advertising / Media    8000.0  15000.0  Monthly  \n",
       "3  Senior Management  Information Technology   8000.0  11000.0  Monthly  \n",
       "4       Professional  Information Technology   6000.0   6500.0  Monthly  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Obtain job deatils for each of the 4,000 Data related job roles scrapped in Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create additional columns in jobs Dataframe\n",
    "jobs = jobs.reindex(columns=['link', 'employer', 'location', 'employment_type', 'seniority', 'sector', \n",
    "                             'pay_min', 'pay_max', 'pay_type', 'about', 'rr', 'requirements'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900\n",
      "1950\n",
      "2000\n",
      "2050\n",
      "2100\n",
      "2150\n",
      "2200\n",
      "2250\n",
      "2300\n",
      "2350\n",
      "2400\n",
      "2450\n",
      "2500\n",
      "2550\n",
      "2600\n",
      "2650\n",
      "2700\n",
      "2750\n",
      "2800\n",
      "2850\n",
      "2900\n",
      "2950\n",
      "3000\n",
      "3050\n",
      "3100\n",
      "3150\n",
      "3200\n",
      "3250\n",
      "3300\n",
      "3350\n",
      "3400\n",
      "3450\n",
      "3500\n",
      "3550\n",
      "3600\n",
      "3650\n",
      "3700\n",
      "3750\n",
      "3800\n",
      "3850\n",
      "3900\n",
      "3950\n"
     ]
    }
   ],
   "source": [
    "for i in range (1860,len(jobs)):\n",
    "    \n",
    "    if i%50==0:\n",
    "        print (i)\n",
    "        \n",
    "    if i!=0 and i%300==0:\n",
    "            jobs.to_csv(\"./jobs{}.csv\" .format(i))\n",
    "    \n",
    "    # Set the URL of the listing.\n",
    "    url = \"https://www.mycareersfuture.sg\"+jobs.loc[i]['link']\n",
    "\n",
    "    # Visit page with Selenium driver.\n",
    "    driver = webdriver.Chrome(executable_path=\"./chromedriver/chromedriver\", options=options)\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait 8 seconds.\n",
    "    sleep(8)\n",
    "\n",
    "    # Grab the page source.\n",
    "    html = driver.page_source\n",
    "\n",
    "    # Pass page source to Beautifulsoup\n",
    "    listing = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # Close Driver\n",
    "    driver.close()\n",
    "    \n",
    "    #Extract information from listing\n",
    "\n",
    "    # About Company\n",
    "    try:\n",
    "        about = listing.find('div', {'class':'black-70 f6 lh-copy break-word op-after pt1 mh100-sp of-hide-sp'}).find_all('p')[1].text\n",
    "    except:\n",
    "        about = np.nan\n",
    "   \n",
    "    # Roles & Responsibilities\n",
    "    try:\n",
    "        rr = listing.find('div', {'id':'description-content'}).text\n",
    "    except:\n",
    "        rr = np.nan\n",
    "    \n",
    "    # Requirements\n",
    "    try:\n",
    "        requirements = listing.find('div', {'id':'requirements-content'}).text\n",
    "    except:\n",
    "        requirements = np.nan\n",
    "        \n",
    "    # Update Dataframe with listing information\n",
    "    jobs.loc[i,['about', 'rr', 'requirements']] = [about, rr, requirements]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs.to_csv(\"./jobslist.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
